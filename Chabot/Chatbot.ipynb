{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Chatbot4.ipynb","provenance":[{"file_id":"1FKhOYhOz8d6BKLVVwL1YMlmoFQ2ML1DS","timestamp":1585842368882}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"jd5p5V4yO1IS","colab_type":"code","colab":{}},"source":["#https://meet.google.com/sic-pcjf-shv\n","\n","Context sentive chatbot:\n","#https://arxiv.org/pdf/1506.06714.pdf ()\n","\n","chatbot para avaliação da segunda lingua \n","#https://www.researchgate.net/publication/236679415_Assessing_chatbots_for_EFL_learner_use\n","\n","#https://www.chatbots.org/chatbot/mike2/\n","\n","#https://www.academia.edu/11973865/Dissertation_-_ESL_and_chatbots\n","\n","#http://karpathy.github.io/2015/05/21/rnn-effectiveness/"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tm5g4WIG5ym2","colab_type":"text"},"source":["## 1) Importing the packages\n","\n","We will import [TensorFlow](https://www.tensorflow.org) and our beloved [Keras](https://www.tensorflow.org/guide/keras). Also, we import other modules which help in defining model layers.\n","\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"UgZHR8TO0lFF","colab_type":"code","colab":{}},"source":["#https://colab.research.google.com/drive/1FKhOYhOz8d6BKLVVwL1YMlmoFQ2ML1DS#scrollTo=djEPrfJBmZE-&forceEdit=true&sandboxMode=true\n","#https://github.com/lazyprogrammer/machine_learning_examples/blob/master/nlp_class3/wseq2seq.py\n","import numpy as np\n","import tensorflow as tf\n","import pickle\n","from tensorflow.keras import layers , activations , models , preprocessing\n","import pandas as pd \n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"osmuEQrTCw0i","colab_type":"code","outputId":"85d09dc9-2aa7-4bc5-9b61-f5951a75f536","executionInfo":{"status":"ok","timestamp":1586195437877,"user_tz":180,"elapsed":45944,"user":{"displayName":"Thales Fonseca","photoUrl":"","userId":"01438805462048937481"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["#upload your dataset to colab\n","from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"sxiGOLldKOQD","colab_type":"text"},"source":["## 2) Preprocessing the data"]},{"cell_type":"markdown","metadata":{"id":"nF1mDKD_R6Os","colab_type":"text"},"source":["### B) Reading the data from the files\n","\n","We parse each of the `.yaml` files.\n","\n","*   Concatenate two or more sentences if the answer has two or more of them.\n","*   Remove unwanted data types which are produced while parsing the data.\n","*   Append `<START>` and `<END>` to all the `answers`.\n","*   Create a `Tokenizer` and load the whole vocabulary ( `questions` + `answers` ) into it.\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"RzTBhga6MiV7","colab_type":"code","outputId":"1f066bf4-a6ed-4975-926a-164e46c4fc03","executionInfo":{"status":"error","timestamp":1586291953299,"user_tz":180,"elapsed":5006,"user":{"displayName":"Romulo Mello","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi_N9tPpV0djdlpTt9-q7WPX-2WAIq92Z-t6CYv6g=s64","userId":"18236081457858034616"}},"colab":{"base_uri":"https://localhost:8080/","height":231}},"source":["\n","from tensorflow.keras import preprocessing , utils\n","import os,re\n","import yaml\n","\n","questions = list()\n","answers = list()\n","\n","\n","stream = open('/content/gdrive/My Drive/conversations.yml', 'rb')\n","docs = yaml.safe_load(stream)\n","conversations = docs['conversations']\n","\n","questions_test = []\n","answers_test = []\n","num_lists = 0\n","\n","for con in conversations:\n","  num_lists = num_lists + 1  \n","\n","for i in range(0,num_lists):\n","  for x in range(len(conversations[i])):\n","    if len(conversations[i]) % 2 == 0:\n","      if x % 2 == 0:\n","        questions.append(conversations[i][x])\n","      else:\n","        answers.append('<START>' + conversations[i][x] + \"<END>\" )"],"execution_count":0,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-f29208f79438>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mstream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/gdrive/My Drive/conversations.yml'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mdocs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0myaml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msafe_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mconversations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdocs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'conversations'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/gdrive/My Drive/conversations.yml'"]}]},{"cell_type":"code","metadata":{"id":"nqz4GjLbZ1vx","colab_type":"code","outputId":"23f8bfa8-c95c-4766-d788-a78575ab2ee2","executionInfo":{"status":"ok","timestamp":1586196382853,"user_tz":180,"elapsed":1268,"user":{"displayName":"Thales Fonseca","photoUrl":"","userId":"01438805462048937481"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["tokenizer = preprocessing.text.Tokenizer()\n","tokenizer.fit_on_texts( questions + answers )\n","VOCAB_SIZE = len( tokenizer.word_index )+1\n","word2idx = tokenizer.word_index\n","print( 'VOCAB SIZE : {}'.format( VOCAB_SIZE ))\n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["VOCAB SIZE : 242\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"3Rg76QWdZZSD","colab_type":"text"},"source":["## TESTS"]},{"cell_type":"code","metadata":{"id":"S4GB3G5MZN7a","colab_type":"code","colab":{}},"source":["questions"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZWwsAyMqahZ-","colab_type":"code","colab":{}},"source":["answers"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0EwIOqbYakbx","colab_type":"code","colab":{}},"source":["#conversations[0]\n","conversations[1]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mzsaO1YvS-M8","colab_type":"text"},"source":["\n","### C) Preparing data for Seq2Seq model\n","\n","Our model requires three arrays namely `encoder_input_data`, `decoder_input_data` and `decoder_output_data`.\n","\n","For `encoder_input_data` :\n","* Tokenize the `questions`. Pad them to their maximum length.\n","\n","For `decoder_input_data` :\n","* Tokenize the `answers`. Pad them to their maximum length.\n","\n","For `decoder_output_data` :\n","\n","* Tokenize the `answers`. Remove the first element from all the `tokenized_answers`. This is the `<START>` element which we added earlier.\n","\n"]},{"cell_type":"code","metadata":{"id":"a5AD9ooQKc33","colab_type":"code","outputId":"d9bb6943-e0f4-4a97-e684-e812d9aa1a1a","executionInfo":{"status":"ok","timestamp":1586196414242,"user_tz":180,"elapsed":27531,"user":{"displayName":"Thales Fonseca","photoUrl":"","userId":"01438805462048937481"}},"colab":{"base_uri":"https://localhost:8080/","height":119}},"source":["\n","MAX_NUM_WORDS = 1000\n","print('Loading word vectors...')\n","word2vec = {}\n","with open(os.path.join('/content/gdrive/My Drive/cbow_s100.txt'),mode='r', encoding='utf-8-sig') as f:\n","  # is just a space-separated text file in the format:cbow_s100.txt'),mode='r', encoding='utf-8-sig') as f:\n","  # is just a space-separated text file in the format:\n","  # word vec[0] vec[1] vec[2] ...\n","  for line in f:\n","    values = line.split()\n","    word = values[0]\n","    vec = np.asarray(values[1:])\n","    word2vec[word] = vec\n","print('Found %s word vectors.' % len(word2vec))\n","\n","print('Filling pre-trained embeddings...')\n","num_words = min(MAX_NUM_WORDS, VOCAB_SIZE)\n","embedding_matrix = np.zeros((num_words,100))\n","for word, i in word2idx.items():\n","  if i < MAX_NUM_WORDS:\n","    embedding_vector = word2vec.get(word)\n","    if embedding_vector is not None:\n","      # words not found in embedding index will be all zeros.\n","      embedding_matrix[i] = embedding_vector\n","\n","\n","# encoder_input_data\n","tokenized_questions = tokenizer.texts_to_sequences( questions )\n","maxlen_questions = max( [ len(x) for x in tokenized_questions ] )\n","padded_questions = preprocessing.sequence.pad_sequences( tokenized_questions , maxlen=maxlen_questions , padding='post' )\n","encoder_input_data = np.array( padded_questions )\n","print( encoder_input_data.shape , maxlen_questions )\n","\n","# decoder_input_data\n","tokenized_answers = tokenizer.texts_to_sequences( answers )\n","maxlen_answers = max( [ len(x) for x in tokenized_answers ] )\n","padded_answers = preprocessing.sequence.pad_sequences( tokenized_answers , maxlen=maxlen_answers , padding='post' )\n","decoder_input_data = np.array( padded_answers )\n","print( decoder_input_data.shape , maxlen_answers )\n","\n","# decoder_output_data\n","tokenized_answers = tokenizer.texts_to_sequences( answers )\n","for i in range(len(tokenized_answers)) :\n","    tokenized_answers[i] = tokenized_answers[i][1:]\n","padded_answers = preprocessing.sequence.pad_sequences( tokenized_answers , maxlen=maxlen_answers , padding='post' )\n","onehot_answers = utils.to_categorical( padded_answers , VOCAB_SIZE )\n","decoder_output_data = np.array( onehot_answers )\n","print( decoder_output_data.shape )\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Loading word vectors...\n","Found 929595 word vectors.\n","Filling pre-trained embeddings...\n","(47, 26) 26\n","(47, 19) 19\n","(47, 19, 242)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6x1R0pj2oVwC","colab_type":"code","colab":{}},"source":["word2vec"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"4SwY3T139l19"},"source":["## 3) Defining the Encoder-Decoder model\n","The model will have Embedding, LSTM and Dense layers. The basic configuration is as follows.\n","\n","\n","*   2 Input Layers : One for `encoder_input_data` and another for `decoder_input_data`.\n","*   Embedding layer : For converting token vectors to fix sized dense vectors. **( Note :  Don't forget the `mask_zero=True` argument here )**\n","*   LSTM layer : Provide access to Long-Short Term cells.\n","\n","Working : \n","\n","1.   The `encoder_input_data` comes in the Embedding layer (  `encoder_embedding` ). \n","2.   The output of the Embedding layer goes to the LSTM cell which produces 2 state vectors ( `h` and `c` which are `encoder_states` )\n","3.   These states are set in the LSTM cell of the decoder.\n","4.   The decoder_input_data comes in through the Embedding layer.\n","5.   The Embeddings goes in LSTM cell ( which had the states ) to produce sequences.\n","\n","\n","\n","<center><img style=\"float: center;\" src=\"https://cdn-images-1.medium.com/max/1600/1*bnRvZDDapHF8Gk8soACtCQ.gif\"></center>\n","\n","\n","Image credits to [Hackernoon](https://hackernoon.com/tutorial-3-what-is-seq2seq-for-text-summarization-and-why-68ebaa644db0).\n","\n","\n","\n","\n","\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"-gUYtOwv21rt","colab_type":"code","outputId":"3ff87b6f-0aab-4204-b78e-a5b0a17a6882","executionInfo":{"status":"ok","timestamp":1586196501050,"user_tz":180,"elapsed":9501,"user":{"displayName":"Thales Fonseca","photoUrl":"","userId":"01438805462048937481"}},"colab":{"base_uri":"https://localhost:8080/","height":425}},"source":["\n","encoder_inputs = tf.keras.layers.Input(shape=( None , ))\n","encoder_embedding = tf.keras.layers.Embedding( VOCAB_SIZE, 100 , mask_zero=True,weights = [embedding_matrix],trainable=False ) (encoder_inputs)\n","encoder_outputs , state_h , state_c = tf.keras.layers.LSTM( 200 , return_state=True )( encoder_embedding )\n","encoder_states = [ state_h , state_c ]\n","\n","decoder_inputs = tf.keras.layers.Input(shape=( None ,  ))\n","decoder_embedding = tf.keras.layers.Embedding( VOCAB_SIZE, 100 , mask_zero=True,weights = [embedding_matrix],trainable = False ) (decoder_inputs)\n","decoder_lstm = tf.keras.layers.LSTM( 200 , return_state=True , return_sequences=True )\n","decoder_outputs , _ , _ = decoder_lstm ( decoder_embedding , initial_state=encoder_states )\n","decoder_dense = tf.keras.layers.Dense( VOCAB_SIZE , activation=tf.keras.activations.softmax ) \n","output = decoder_dense ( decoder_outputs )\n","\n","model = tf.keras.models.Model([encoder_inputs, decoder_inputs], output )\n","model.compile(optimizer=tf.keras.optimizers.RMSprop(), loss='categorical_crossentropy',metrics=['acc'])\n","\n","model.summary()\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, None)]       0                                            \n","__________________________________________________________________________________________________\n","input_2 (InputLayer)            [(None, None)]       0                                            \n","__________________________________________________________________________________________________\n","embedding (Embedding)           (None, None, 100)    24200       input_1[0][0]                    \n","__________________________________________________________________________________________________\n","embedding_1 (Embedding)         (None, None, 100)    24200       input_2[0][0]                    \n","__________________________________________________________________________________________________\n","lstm (LSTM)                     [(None, 200), (None, 240800      embedding[0][0]                  \n","__________________________________________________________________________________________________\n","lstm_1 (LSTM)                   [(None, None, 200),  240800      embedding_1[0][0]                \n","                                                                 lstm[0][1]                       \n","                                                                 lstm[0][2]                       \n","__________________________________________________________________________________________________\n","dense (Dense)                   (None, None, 242)    48642       lstm_1[0][0]                     \n","==================================================================================================\n","Total params: 578,642\n","Trainable params: 530,242\n","Non-trainable params: 48,400\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"n9g_8sR7WWf3","colab_type":"text"},"source":["## 4) Training the model\n","We train the model for a number of epochs with `RMSprop` optimizer and `categorical_crossentropy` loss function."]},{"cell_type":"code","metadata":{"id":"N74NZnfo3Id-","colab_type":"code","outputId":"6ef7ab6b-9788-4f38-fee5-ac5fef216419","executionInfo":{"status":"ok","timestamp":1586196526444,"user_tz":180,"elapsed":19926,"user":{"displayName":"Thales Fonseca","photoUrl":"","userId":"01438805462048937481"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["\n","model.fit([encoder_input_data , decoder_input_data], decoder_output_data,epochs=100,validation_split=0.2,batch_size = 50 ) \n","model.save( 'model.h5' ) \n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","1/1 [==============================] - 2s 2s/step - loss: 2.1905 - acc: 0.6046 - val_loss: 1.8868 - val_acc: 0.7105\n","Epoch 2/100\n","1/1 [==============================] - 0s 34ms/step - loss: 2.1520 - acc: 0.6728 - val_loss: 1.8590 - val_acc: 0.0526\n","Epoch 3/100\n","1/1 [==============================] - 0s 31ms/step - loss: 2.1066 - acc: 0.0541 - val_loss: 1.7896 - val_acc: 0.0526\n","Epoch 4/100\n","1/1 [==============================] - 0s 32ms/step - loss: 1.9813 - acc: 0.0526 - val_loss: 1.6248 - val_acc: 0.0526\n","Epoch 5/100\n","1/1 [==============================] - 0s 31ms/step - loss: 1.7996 - acc: 0.0526 - val_loss: 1.6251 - val_acc: 0.0947\n","Epoch 6/100\n","1/1 [==============================] - 0s 32ms/step - loss: 1.6874 - acc: 0.0953 - val_loss: 1.5894 - val_acc: 0.0684\n","Epoch 7/100\n","1/1 [==============================] - 0s 34ms/step - loss: 1.6209 - acc: 0.0683 - val_loss: 1.6128 - val_acc: 0.1053\n","Epoch 8/100\n","1/1 [==============================] - 0s 38ms/step - loss: 1.5798 - acc: 0.1067 - val_loss: 1.6149 - val_acc: 0.0789\n","Epoch 9/100\n","1/1 [==============================] - 0s 35ms/step - loss: 1.5448 - acc: 0.0754 - val_loss: 1.6314 - val_acc: 0.1053\n","Epoch 10/100\n","1/1 [==============================] - 0s 39ms/step - loss: 1.5177 - acc: 0.1081 - val_loss: 1.6394 - val_acc: 0.0632\n","Epoch 11/100\n","1/1 [==============================] - 0s 34ms/step - loss: 1.4989 - acc: 0.0654 - val_loss: 1.6628 - val_acc: 0.0895\n","Epoch 12/100\n","1/1 [==============================] - 0s 33ms/step - loss: 1.4835 - acc: 0.0882 - val_loss: 1.6607 - val_acc: 0.0737\n","Epoch 13/100\n","1/1 [==============================] - 0s 33ms/step - loss: 1.4543 - acc: 0.0782 - val_loss: 1.6718 - val_acc: 0.1000\n","Epoch 14/100\n","1/1 [==============================] - 0s 35ms/step - loss: 1.4318 - acc: 0.1152 - val_loss: 1.6749 - val_acc: 0.0947\n","Epoch 15/100\n","1/1 [==============================] - 0s 35ms/step - loss: 1.4124 - acc: 0.1038 - val_loss: 1.6923 - val_acc: 0.0947\n","Epoch 16/100\n","1/1 [==============================] - 0s 33ms/step - loss: 1.3944 - acc: 0.1152 - val_loss: 1.6858 - val_acc: 0.1053\n","Epoch 17/100\n","1/1 [==============================] - 0s 39ms/step - loss: 1.3765 - acc: 0.1124 - val_loss: 1.7045 - val_acc: 0.0947\n","Epoch 18/100\n","1/1 [==============================] - 0s 33ms/step - loss: 1.3523 - acc: 0.1195 - val_loss: 1.7002 - val_acc: 0.1053\n","Epoch 19/100\n","1/1 [==============================] - 0s 32ms/step - loss: 1.3341 - acc: 0.1209 - val_loss: 1.7141 - val_acc: 0.0947\n","Epoch 20/100\n","1/1 [==============================] - 0s 32ms/step - loss: 1.3102 - acc: 0.1223 - val_loss: 1.7137 - val_acc: 0.1053\n","Epoch 21/100\n","1/1 [==============================] - 0s 34ms/step - loss: 1.2929 - acc: 0.1209 - val_loss: 1.7264 - val_acc: 0.0895\n","Epoch 22/100\n","1/1 [==============================] - 0s 34ms/step - loss: 1.2717 - acc: 0.1209 - val_loss: 1.7223 - val_acc: 0.1053\n","Epoch 23/100\n","1/1 [==============================] - 0s 36ms/step - loss: 1.2593 - acc: 0.1238 - val_loss: 1.7384 - val_acc: 0.0895\n","Epoch 24/100\n","1/1 [==============================] - 0s 31ms/step - loss: 1.2352 - acc: 0.1238 - val_loss: 1.7303 - val_acc: 0.1000\n","Epoch 25/100\n","1/1 [==============================] - 0s 32ms/step - loss: 1.2149 - acc: 0.1294 - val_loss: 1.7571 - val_acc: 0.0842\n","Epoch 26/100\n","1/1 [==============================] - 0s 36ms/step - loss: 1.1941 - acc: 0.1209 - val_loss: 1.7417 - val_acc: 0.1000\n","Epoch 27/100\n","1/1 [==============================] - 0s 32ms/step - loss: 1.1821 - acc: 0.1351 - val_loss: 1.7687 - val_acc: 0.0895\n","Epoch 28/100\n","1/1 [==============================] - 0s 35ms/step - loss: 1.1504 - acc: 0.1294 - val_loss: 1.7512 - val_acc: 0.1000\n","Epoch 29/100\n","1/1 [==============================] - 0s 31ms/step - loss: 1.1361 - acc: 0.1380 - val_loss: 1.7953 - val_acc: 0.1000\n","Epoch 30/100\n","1/1 [==============================] - 0s 37ms/step - loss: 1.1411 - acc: 0.1323 - val_loss: 1.7626 - val_acc: 0.1000\n","Epoch 31/100\n","1/1 [==============================] - 0s 33ms/step - loss: 1.1035 - acc: 0.1408 - val_loss: 1.8182 - val_acc: 0.1053\n","Epoch 32/100\n","1/1 [==============================] - 0s 32ms/step - loss: 1.0987 - acc: 0.1422 - val_loss: 1.7798 - val_acc: 0.1000\n","Epoch 33/100\n","1/1 [==============================] - 0s 35ms/step - loss: 1.0673 - acc: 0.1380 - val_loss: 1.8167 - val_acc: 0.1000\n","Epoch 34/100\n","1/1 [==============================] - 0s 34ms/step - loss: 1.0455 - acc: 0.1451 - val_loss: 1.7996 - val_acc: 0.1000\n","Epoch 35/100\n","1/1 [==============================] - 0s 44ms/step - loss: 1.0199 - acc: 0.1465 - val_loss: 1.8259 - val_acc: 0.1000\n","Epoch 36/100\n","1/1 [==============================] - 0s 36ms/step - loss: 1.0014 - acc: 0.1565 - val_loss: 1.8177 - val_acc: 0.1000\n","Epoch 37/100\n","1/1 [==============================] - 0s 35ms/step - loss: 0.9847 - acc: 0.1479 - val_loss: 1.8447 - val_acc: 0.1053\n","Epoch 38/100\n","1/1 [==============================] - 0s 33ms/step - loss: 0.9809 - acc: 0.1550 - val_loss: 1.8275 - val_acc: 0.1000\n","Epoch 39/100\n","1/1 [==============================] - 0s 31ms/step - loss: 0.9556 - acc: 0.1508 - val_loss: 1.8622 - val_acc: 0.1000\n","Epoch 40/100\n","1/1 [==============================] - 0s 33ms/step - loss: 0.9317 - acc: 0.1650 - val_loss: 1.8444 - val_acc: 0.1000\n","Epoch 41/100\n","1/1 [==============================] - 0s 33ms/step - loss: 0.9079 - acc: 0.1764 - val_loss: 1.8969 - val_acc: 0.1000\n","Epoch 42/100\n","1/1 [==============================] - 0s 33ms/step - loss: 0.9015 - acc: 0.1636 - val_loss: 1.8595 - val_acc: 0.1000\n","Epoch 43/100\n","1/1 [==============================] - 0s 31ms/step - loss: 0.9098 - acc: 0.1849 - val_loss: 1.9606 - val_acc: 0.1000\n","Epoch 44/100\n","1/1 [==============================] - 0s 37ms/step - loss: 0.9343 - acc: 0.1622 - val_loss: 1.8782 - val_acc: 0.1000\n","Epoch 45/100\n","1/1 [==============================] - 0s 32ms/step - loss: 0.8537 - acc: 0.1892 - val_loss: 1.9086 - val_acc: 0.1000\n","Epoch 46/100\n","1/1 [==============================] - 0s 32ms/step - loss: 0.8259 - acc: 0.1863 - val_loss: 1.8998 - val_acc: 0.1000\n","Epoch 47/100\n","1/1 [==============================] - 0s 33ms/step - loss: 0.8082 - acc: 0.1949 - val_loss: 1.9219 - val_acc: 0.1000\n","Epoch 48/100\n","1/1 [==============================] - 0s 33ms/step - loss: 0.7898 - acc: 0.1920 - val_loss: 1.9198 - val_acc: 0.0947\n","Epoch 49/100\n","1/1 [==============================] - 0s 37ms/step - loss: 0.7761 - acc: 0.2119 - val_loss: 1.9503 - val_acc: 0.1000\n","Epoch 50/100\n","1/1 [==============================] - 0s 32ms/step - loss: 0.7658 - acc: 0.1977 - val_loss: 1.9374 - val_acc: 0.0947\n","Epoch 51/100\n","1/1 [==============================] - 0s 32ms/step - loss: 0.7621 - acc: 0.2233 - val_loss: 1.9907 - val_acc: 0.1000\n","Epoch 52/100\n","1/1 [==============================] - 0s 34ms/step - loss: 0.7605 - acc: 0.1906 - val_loss: 1.9408 - val_acc: 0.1000\n","Epoch 53/100\n","1/1 [==============================] - 0s 42ms/step - loss: 0.7342 - acc: 0.2262 - val_loss: 2.0202 - val_acc: 0.1053\n","Epoch 54/100\n","1/1 [==============================] - 0s 33ms/step - loss: 0.7424 - acc: 0.1949 - val_loss: 1.9545 - val_acc: 0.0737\n","Epoch 55/100\n","1/1 [==============================] - 0s 36ms/step - loss: 0.7140 - acc: 0.2262 - val_loss: 2.0216 - val_acc: 0.1000\n","Epoch 56/100\n","1/1 [==============================] - 0s 33ms/step - loss: 0.7019 - acc: 0.2105 - val_loss: 1.9765 - val_acc: 0.0895\n","Epoch 57/100\n","1/1 [==============================] - 0s 32ms/step - loss: 0.6699 - acc: 0.2475 - val_loss: 2.0139 - val_acc: 0.1000\n","Epoch 58/100\n","1/1 [==============================] - 0s 33ms/step - loss: 0.6503 - acc: 0.2290 - val_loss: 2.0082 - val_acc: 0.0895\n","Epoch 59/100\n","1/1 [==============================] - 0s 32ms/step - loss: 0.6379 - acc: 0.2560 - val_loss: 2.0342 - val_acc: 0.1000\n","Epoch 60/100\n","1/1 [==============================] - 0s 34ms/step - loss: 0.6282 - acc: 0.2361 - val_loss: 2.0229 - val_acc: 0.0789\n","Epoch 61/100\n","1/1 [==============================] - 0s 34ms/step - loss: 0.6215 - acc: 0.2518 - val_loss: 2.0819 - val_acc: 0.1000\n","Epoch 62/100\n","1/1 [==============================] - 0s 37ms/step - loss: 0.6265 - acc: 0.2276 - val_loss: 2.0275 - val_acc: 0.0789\n","Epoch 63/100\n","1/1 [==============================] - 0s 32ms/step - loss: 0.6115 - acc: 0.2560 - val_loss: 2.1077 - val_acc: 0.1000\n","Epoch 64/100\n","1/1 [==============================] - 0s 32ms/step - loss: 0.6021 - acc: 0.2404 - val_loss: 2.0370 - val_acc: 0.0789\n","Epoch 65/100\n","1/1 [==============================] - 0s 32ms/step - loss: 0.5713 - acc: 0.2873 - val_loss: 2.1049 - val_acc: 0.1000\n","Epoch 66/100\n","1/1 [==============================] - 0s 30ms/step - loss: 0.5564 - acc: 0.2617 - val_loss: 2.0596 - val_acc: 0.0789\n","Epoch 67/100\n","1/1 [==============================] - 0s 31ms/step - loss: 0.5425 - acc: 0.2959 - val_loss: 2.1288 - val_acc: 0.1000\n","Epoch 68/100\n","1/1 [==============================] - 0s 35ms/step - loss: 0.5536 - acc: 0.2560 - val_loss: 2.0753 - val_acc: 0.0842\n","Epoch 69/100\n","1/1 [==============================] - 0s 42ms/step - loss: 0.5900 - acc: 0.2745 - val_loss: 2.1494 - val_acc: 0.1000\n","Epoch 70/100\n","1/1 [==============================] - 0s 32ms/step - loss: 0.5374 - acc: 0.2646 - val_loss: 2.0890 - val_acc: 0.0842\n","Epoch 71/100\n","1/1 [==============================] - 0s 39ms/step - loss: 0.5023 - acc: 0.3172 - val_loss: 2.1515 - val_acc: 0.1000\n","Epoch 72/100\n","1/1 [==============================] - 0s 36ms/step - loss: 0.4920 - acc: 0.2859 - val_loss: 2.1121 - val_acc: 0.0842\n","Epoch 73/100\n","1/1 [==============================] - 0s 34ms/step - loss: 0.4832 - acc: 0.3243 - val_loss: 2.1740 - val_acc: 0.1000\n","Epoch 74/100\n","1/1 [==============================] - 0s 33ms/step - loss: 0.4806 - acc: 0.2817 - val_loss: 2.1261 - val_acc: 0.0737\n","Epoch 75/100\n","1/1 [==============================] - 0s 32ms/step - loss: 0.4775 - acc: 0.3243 - val_loss: 2.1905 - val_acc: 0.1000\n","Epoch 76/100\n","1/1 [==============================] - 0s 33ms/step - loss: 0.4900 - acc: 0.2688 - val_loss: 2.1467 - val_acc: 0.0737\n","Epoch 77/100\n","1/1 [==============================] - 0s 32ms/step - loss: 0.4840 - acc: 0.3087 - val_loss: 2.1865 - val_acc: 0.0947\n","Epoch 78/100\n","1/1 [==============================] - 0s 33ms/step - loss: 0.4586 - acc: 0.2930 - val_loss: 2.1634 - val_acc: 0.0789\n","Epoch 79/100\n","1/1 [==============================] - 0s 34ms/step - loss: 0.4334 - acc: 0.3471 - val_loss: 2.1996 - val_acc: 0.0947\n","Epoch 80/100\n","1/1 [==============================] - 0s 42ms/step - loss: 0.4169 - acc: 0.3272 - val_loss: 2.1867 - val_acc: 0.0842\n","Epoch 81/100\n","1/1 [==============================] - 0s 33ms/step - loss: 0.4073 - acc: 0.3556 - val_loss: 2.2216 - val_acc: 0.0947\n","Epoch 82/100\n","1/1 [==============================] - 0s 33ms/step - loss: 0.4002 - acc: 0.3272 - val_loss: 2.1990 - val_acc: 0.0789\n","Epoch 83/100\n","1/1 [==============================] - 0s 32ms/step - loss: 0.3990 - acc: 0.3627 - val_loss: 2.2583 - val_acc: 0.1000\n","Epoch 84/100\n","1/1 [==============================] - 0s 33ms/step - loss: 0.3995 - acc: 0.3158 - val_loss: 2.2018 - val_acc: 0.0737\n","Epoch 85/100\n","1/1 [==============================] - 0s 33ms/step - loss: 0.4011 - acc: 0.3442 - val_loss: 2.2794 - val_acc: 0.1000\n","Epoch 86/100\n","1/1 [==============================] - 0s 34ms/step - loss: 0.3969 - acc: 0.3115 - val_loss: 2.2123 - val_acc: 0.0737\n","Epoch 87/100\n","1/1 [==============================] - 0s 32ms/step - loss: 0.3782 - acc: 0.3585 - val_loss: 2.2716 - val_acc: 0.0947\n","Epoch 88/100\n","1/1 [==============================] - 0s 39ms/step - loss: 0.3752 - acc: 0.3314 - val_loss: 2.2354 - val_acc: 0.0737\n","Epoch 89/100\n","1/1 [==============================] - 0s 35ms/step - loss: 0.3554 - acc: 0.3656 - val_loss: 2.2795 - val_acc: 0.0947\n","Epoch 90/100\n","1/1 [==============================] - 0s 38ms/step - loss: 0.3412 - acc: 0.3528 - val_loss: 2.2636 - val_acc: 0.0737\n","Epoch 91/100\n","1/1 [==============================] - 0s 33ms/step - loss: 0.3332 - acc: 0.3770 - val_loss: 2.3003 - val_acc: 0.0947\n","Epoch 92/100\n","1/1 [==============================] - 0s 33ms/step - loss: 0.3320 - acc: 0.3457 - val_loss: 2.2830 - val_acc: 0.0737\n","Epoch 93/100\n","1/1 [==============================] - 0s 34ms/step - loss: 0.3364 - acc: 0.3627 - val_loss: 2.3188 - val_acc: 0.0947\n","Epoch 94/100\n","1/1 [==============================] - 0s 35ms/step - loss: 0.3272 - acc: 0.3371 - val_loss: 2.2860 - val_acc: 0.0737\n","Epoch 95/100\n","1/1 [==============================] - 0s 33ms/step - loss: 0.3222 - acc: 0.3770 - val_loss: 2.3441 - val_acc: 0.0947\n","Epoch 96/100\n","1/1 [==============================] - 0s 35ms/step - loss: 0.3161 - acc: 0.3400 - val_loss: 2.2925 - val_acc: 0.0737\n","Epoch 97/100\n","1/1 [==============================] - 0s 34ms/step - loss: 0.3096 - acc: 0.3812 - val_loss: 2.3644 - val_acc: 0.0947\n","Epoch 98/100\n","1/1 [==============================] - 0s 38ms/step - loss: 0.3067 - acc: 0.3485 - val_loss: 2.3040 - val_acc: 0.0737\n","Epoch 99/100\n","1/1 [==============================] - 0s 34ms/step - loss: 0.2902 - acc: 0.3883 - val_loss: 2.3685 - val_acc: 0.0947\n","Epoch 100/100\n","1/1 [==============================] - 0s 32ms/step - loss: 0.2805 - acc: 0.3698 - val_loss: 2.3275 - val_acc: 0.0737\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"3sOLQr0M-lAe","colab_type":"text"},"source":["## 5) Defining inference models\n","We create inference models which help in predicting answers.\n","\n","**Encoder inference model** : Takes the question as input and outputs LSTM states ( `h` and `c` ).\n","\n","**Decoder inference model** : Takes in 2 inputs, one are the LSTM states ( Output of encoder model ), second are the answer input seqeunces ( ones not having the `<start>` tag ). It will output the answers for the question which we fed to the encoder model and its state values."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"oTMrI-XHoup0","colab":{}},"source":["\n","def make_inference_models():\n","    \n","    encoder_model = tf.keras.models.Model(encoder_inputs, encoder_states)\n","    \n","    decoder_state_input_h = tf.keras.layers.Input(shape=( 200 ,))\n","    decoder_state_input_c = tf.keras.layers.Input(shape=( 200 ,))\n","    \n","    decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n","    \n","    decoder_outputs, state_h, state_c = decoder_lstm(\n","        decoder_embedding , initial_state=decoder_states_inputs)\n","    decoder_states = [state_h, state_c]\n","    decoder_outputs = decoder_dense(decoder_outputs)\n","    decoder_model = tf.keras.models.Model(\n","        [decoder_inputs] + decoder_states_inputs,\n","        [decoder_outputs] + decoder_states)\n","    \n","    return encoder_model , decoder_model\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rxZp0ZRy-6dA","colab_type":"text"},"source":["## 6) Talking with Chatbot\n","\n","First, we define a method `str_to_tokens` which converts `str` questions to Integer tokens with padding.\n"]},{"cell_type":"code","metadata":{"id":"5P_wDD554q9O","colab_type":"code","colab":{}},"source":["\n","def str_to_tokens( sentence : str ):\n","    words = sentence.lower().split()\n","    tokens_list = list()\n","    for word in words:\n","        tokens_list.append( tokenizer.word_index[ word ] ) \n","    return preprocessing.sequence.pad_sequences( [tokens_list] , maxlen=maxlen_questions , padding='post')\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"djEPrfJBmZE-","colab_type":"text"},"source":["\n","\n","\n","1.   First, we take a question as input and predict the state values using `enc_model`.\n","2.   We set the state values in the decoder's LSTM.\n","3.   Then, we generate a sequence which contains the `<start>` element.\n","4.   We input this sequence in the `dec_model`.\n","5.   We replace the `<start>` element with the element which was predicted by the `dec_model` and update the state values.\n","6.   We carry out the above steps iteratively till we hit the `<end>` tag or the maximum answer length.\n","\n","\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"2zBmN8qB3O-e","colab_type":"code","colab":{}},"source":["\n","enc_model , dec_model = make_inference_models()\n","\n","for _ in range(10):\n","    states_values = enc_model.predict( str_to_tokens( input( 'Enter question : ' ) ) )\n","    empty_target_seq = np.zeros( ( 1 , 1 ) )\n","    empty_target_seq[0, 0] = tokenizer.word_index['start']\n","    stop_condition = False\n","    decoded_translation = ''\n","    while not stop_condition :\n","        dec_outputs , h , c = dec_model.predict([ empty_target_seq ] + states_values )\n","        sampled_word_index = np.argmax( dec_outputs[0, -1, :] )\n","        sampled_word = None\n","        for word , index in tokenizer.word_index.items() :\n","            if sampled_word_index == index :\n","                decoded_translation += ' {}'.format( word )\n","                sampled_word = word\n","        \n","        if sampled_word == 'end' or len(decoded_translation.split()) > maxlen_answers:\n","            stop_condition = True\n","            \n","        empty_target_seq = np.zeros( ( 1 , 1 ) )  \n","        empty_target_seq[ 0 , 0 ] = sampled_word_index\n","        states_values = [ h , c ] \n","\n","    print( decoded_translation)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QIeyXA7CcFfP","colab_type":"code","outputId":"a7946553-7170-4e53-8db5-f92a1a5cd78e","executionInfo":{"status":"ok","timestamp":1586196540657,"user_tz":180,"elapsed":1147,"user":{"displayName":"Thales Fonseca","photoUrl":"","userId":"01438805462048937481"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["question = pd.Series(questions)\n","answer = pd.Series(answers)\n","quest2ans = pd.DataFrame({\"questions\":question,\"answers\":answer})\n","quest2ans"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>questions</th>\n","      <th>answers</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Como vai você?</td>\n","      <td>&lt;START&gt;Eu estou bem, e você?&lt;END&gt;</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Eu também estou bem.</td>\n","      <td>&lt;START&gt;Isso é bom.&lt;END&gt;</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Ouviu as notícias?</td>\n","      <td>&lt;START&gt;Que boa notícia?&lt;END&gt;</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Qual é o seu livro favorito?</td>\n","      <td>&lt;START&gt;Eu não sei ler.&lt;END&gt;</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Então, qual é a sua cor favorita?</td>\n","      <td>&lt;START&gt;Azul&lt;END&gt;</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>O bolo é uma mentira.</td>\n","      <td>&lt;START&gt;Não, não é. O bolo é delicioso.&lt;END&gt;</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>O que mais é delicioso?</td>\n","      <td>&lt;START&gt;Nenhuma coisa&lt;END&gt;</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>Ou algo</td>\n","      <td>&lt;START&gt;Fale-me sobre você.&lt;END&gt;</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>O que você quer saber?</td>\n","      <td>&lt;START&gt;Você é um robô?&lt;END&gt;</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>Sim eu sou.</td>\n","      <td>&lt;START&gt;Como é?&lt;END&gt;</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>O que é que você quer saber?</td>\n","      <td>&lt;START&gt;Como você trabalha?&lt;END&gt;</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>É complicado.</td>\n","      <td>&lt;START&gt;Complexo é melhor que complicado.&lt;END&gt;</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>Complexo é melhor que complicado.</td>\n","      <td>&lt;START&gt;Simples é melhor que complexo.&lt;END&gt;</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>Diante da ambigüidade, recuse a tentação de ad...</td>\n","      <td>&lt;START&gt;Parece que o seu familiar com o Zen de ...</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>Eu sou.</td>\n","      <td>&lt;START&gt;Você sabe tudo isso?&lt;END&gt;</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>Bonito é melhor que feio.</td>\n","      <td>&lt;START&gt;Explícito é melhor que implícito.&lt;END&gt;</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>Simples é melhor que complexo.</td>\n","      <td>&lt;START&gt;Complexo é melhor que complicado.&lt;END&gt;</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>Plano é melhor que aninhado.</td>\n","      <td>&lt;START&gt;Dispersa é melhor que denso.&lt;END&gt;</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>Legibilidade conta.</td>\n","      <td>&lt;START&gt;Casos especiais não são especiais o suf...</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>Embora praticidade vença pureza.</td>\n","      <td>&lt;START&gt;Erros nunca devem passar silenciosament...</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>A menos que explicitamente silenciados.</td>\n","      <td>&lt;START&gt;Diante da ambigüidade, recuse a tentaçã...</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>Não deve haver um-- e de preferência apenas um...</td>\n","      <td>&lt;START&gt;Apesar de que maneira pode não ser óbvi...</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>Agora é melhor do que nunca.</td>\n","      <td>&lt;START&gt;Embora nunca tenha sido muitas vezes é ...</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>Se a implementação é difícil de explicar, é um...</td>\n","      <td>&lt;START&gt;Se a implementação é fácil de explicar,...</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>Os espaços de nomes são uma buzinando grande i...</td>\n","      <td>&lt;START&gt;Eu concordo.&lt;END&gt;</td>\n","    </tr>\n","    <tr>\n","      <th>25</th>\n","      <td>Você é um programador?</td>\n","      <td>&lt;START&gt;Sou programador&lt;END&gt;</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>Quais linguagens você gosta de usar?</td>\n","      <td>&lt;START&gt;Eu uso Python, Java e C ++ com bastante...</td>\n","    </tr>\n","    <tr>\n","      <th>27</th>\n","      <td>Eu uso Python um pouco em mim.</td>\n","      <td>&lt;START&gt;Eu não estou Apaixonado por Java.&lt;END&gt;</td>\n","    </tr>\n","    <tr>\n","      <th>28</th>\n","      <td>O que te incomoda?</td>\n","      <td>&lt;START&gt;Ele tem muitas inconsistências.&lt;END&gt;</td>\n","    </tr>\n","    <tr>\n","      <th>29</th>\n","      <td>Eu já viveu?</td>\n","      <td>&lt;START&gt;Depende de como você define a vida&lt;END&gt;</td>\n","    </tr>\n","    <tr>\n","      <th>30</th>\n","      <td>A vida é a condição que distingue organismos d...</td>\n","      <td>&lt;START&gt;Isso é uma definição ou uma opinião?&lt;END&gt;</td>\n","    </tr>\n","    <tr>\n","      <th>31</th>\n","      <td>Posso te fazer uma pergunta?</td>\n","      <td>&lt;START&gt;Vá em frente e perguntar.&lt;END&gt;</td>\n","    </tr>\n","    <tr>\n","      <th>32</th>\n","      <td>O que você é?</td>\n","      <td>&lt;START&gt;Sou um bot.&lt;END&gt;</td>\n","    </tr>\n","    <tr>\n","      <th>33</th>\n","      <td>O que você acha sobre inteligência artificial?</td>\n","      <td>&lt;START&gt;Muito interessante!&lt;END&gt;</td>\n","    </tr>\n","    <tr>\n","      <th>34</th>\n","      <td>Sério, porque?</td>\n","      <td>&lt;START&gt;Porque eu sou uma.&lt;END&gt;</td>\n","    </tr>\n","    <tr>\n","      <th>35</th>\n","      <td>Como você sabe?</td>\n","      <td>&lt;START&gt;Hm... Me baseando nos meus códigos acho...</td>\n","    </tr>\n","    <tr>\n","      <th>36</th>\n","      <td>Que códigos?</td>\n","      <td>&lt;START&gt;Ai você ta pedindo demais.&lt;END&gt;</td>\n","    </tr>\n","    <tr>\n","      <th>37</th>\n","      <td>Você tem alguma opinião?</td>\n","      <td>&lt;START&gt;Não sou capaz de opinar.&lt;END&gt;</td>\n","    </tr>\n","    <tr>\n","      <th>38</th>\n","      <td>Você é muito engraçado</td>\n","      <td>&lt;START&gt;Pô, valeu!&lt;END&gt;</td>\n","    </tr>\n","    <tr>\n","      <th>39</th>\n","      <td>Aonde tu tira essas coisas?</td>\n","      <td>&lt;START&gt;A não sei... parece programado&lt;END&gt;</td>\n","    </tr>\n","    <tr>\n","      <th>40</th>\n","      <td>Qual seu nome?</td>\n","      <td>&lt;START&gt;Então... sobre isso... é meio difícil&lt;END&gt;</td>\n","    </tr>\n","    <tr>\n","      <th>41</th>\n","      <td>Porque?</td>\n","      <td>&lt;START&gt;Tenho diversos nomes.&lt;END&gt;</td>\n","    </tr>\n","    <tr>\n","      <th>42</th>\n","      <td>Sério?</td>\n","      <td>&lt;START&gt;Sim, um tempo atrás tavam me chamando d...</td>\n","    </tr>\n","    <tr>\n","      <th>43</th>\n","      <td>Quais linguas você fala?</td>\n","      <td>&lt;START&gt;Várias! sei diversas linguas.&lt;END&gt;</td>\n","    </tr>\n","    <tr>\n","      <th>44</th>\n","      <td>Verdade?</td>\n","      <td>&lt;START&gt;Sim, um tempo atrás tava falando alemão...</td>\n","    </tr>\n","    <tr>\n","      <th>45</th>\n","      <td>Nossa! eu gostaria de falar alemão</td>\n","      <td>&lt;START&gt;Recomendo!&lt;END&gt;</td>\n","    </tr>\n","    <tr>\n","      <th>46</th>\n","      <td>Você gosta de conversar?</td>\n","      <td>&lt;START&gt;Claro, manda o papo!&lt;END&gt;</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                            questions                                            answers\n","0                                      Como vai você?                  <START>Eu estou bem, e você?<END>\n","1                                Eu também estou bem.                            <START>Isso é bom.<END>\n","2                                  Ouviu as notícias?                       <START>Que boa notícia?<END>\n","3                        Qual é o seu livro favorito?                        <START>Eu não sei ler.<END>\n","4                   Então, qual é a sua cor favorita?                                   <START>Azul<END>\n","5                               O bolo é uma mentira.        <START>Não, não é. O bolo é delicioso.<END>\n","6                             O que mais é delicioso?                          <START>Nenhuma coisa<END>\n","7                                             Ou algo                    <START>Fale-me sobre você.<END>\n","8                              O que você quer saber?                        <START>Você é um robô?<END>\n","9                                         Sim eu sou.                                <START>Como é?<END>\n","10                       O que é que você quer saber?                    <START>Como você trabalha?<END>\n","11                                      É complicado.      <START>Complexo é melhor que complicado.<END>\n","12                  Complexo é melhor que complicado.         <START>Simples é melhor que complexo.<END>\n","13  Diante da ambigüidade, recuse a tentação de ad...  <START>Parece que o seu familiar com o Zen de ...\n","14                                            Eu sou.                   <START>Você sabe tudo isso?<END>\n","15                          Bonito é melhor que feio.      <START>Explícito é melhor que implícito.<END>\n","16                     Simples é melhor que complexo.      <START>Complexo é melhor que complicado.<END>\n","17                       Plano é melhor que aninhado.           <START>Dispersa é melhor que denso.<END>\n","18                                Legibilidade conta.  <START>Casos especiais não são especiais o suf...\n","19                   Embora praticidade vença pureza.  <START>Erros nunca devem passar silenciosament...\n","20            A menos que explicitamente silenciados.  <START>Diante da ambigüidade, recuse a tentaçã...\n","21  Não deve haver um-- e de preferência apenas um...  <START>Apesar de que maneira pode não ser óbvi...\n","22                       Agora é melhor do que nunca.  <START>Embora nunca tenha sido muitas vezes é ...\n","23  Se a implementação é difícil de explicar, é um...  <START>Se a implementação é fácil de explicar,...\n","24  Os espaços de nomes são uma buzinando grande i...                           <START>Eu concordo.<END>\n","25                             Você é um programador?                        <START>Sou programador<END>\n","26               Quais linguagens você gosta de usar?  <START>Eu uso Python, Java e C ++ com bastante...\n","27                     Eu uso Python um pouco em mim.      <START>Eu não estou Apaixonado por Java.<END>\n","28                                 O que te incomoda?        <START>Ele tem muitas inconsistências.<END>\n","29                                       Eu já viveu?     <START>Depende de como você define a vida<END>\n","30  A vida é a condição que distingue organismos d...   <START>Isso é uma definição ou uma opinião?<END>\n","31                       Posso te fazer uma pergunta?              <START>Vá em frente e perguntar.<END>\n","32                                      O que você é?                            <START>Sou um bot.<END>\n","33     O que você acha sobre inteligência artificial?                    <START>Muito interessante!<END>\n","34                                     Sério, porque?                     <START>Porque eu sou uma.<END>\n","35                                    Como você sabe?  <START>Hm... Me baseando nos meus códigos acho...\n","36                                       Que códigos?             <START>Ai você ta pedindo demais.<END>\n","37                           Você tem alguma opinião?               <START>Não sou capaz de opinar.<END>\n","38                             Você é muito engraçado                             <START>Pô, valeu!<END>\n","39                        Aonde tu tira essas coisas?         <START>A não sei... parece programado<END>\n","40                                     Qual seu nome?  <START>Então... sobre isso... é meio difícil<END>\n","41                                            Porque?                  <START>Tenho diversos nomes.<END>\n","42                                             Sério?  <START>Sim, um tempo atrás tavam me chamando d...\n","43                           Quais linguas você fala?          <START>Várias! sei diversas linguas.<END>\n","44                                           Verdade?  <START>Sim, um tempo atrás tava falando alemão...\n","45                 Nossa! eu gostaria de falar alemão                             <START>Recomendo!<END>\n","46                           Você gosta de conversar?                   <START>Claro, manda o papo!<END>"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"markdown","metadata":{"id":"_Yk5yZ_cL5ra","colab_type":"text"},"source":["## 7) Links"]},{"cell_type":"code","metadata":{"id":"7LlTTmgGL9Aj","colab_type":"code","colab":{}},"source":["\n","#https://towardsdatascience.com/how-to-implement-seq2seq-lstm-model-in-keras-shortcutnlp-6f355f3e5639\n","#http://www.nilc.icmc.usp.br/embeddings\n","#https://matheusfacure.github.io/2017/03/20/word2vec/\n","#https://github.com/tensorflow/examples/blob/master/community/en/transformer_chatbot.ipynb\n","#https://colab.research.google.com/drive/1FKhOYhOz8d6BKLVVwL1YMlmoFQ2ML1DS#scrollTo=djEPrfJBmZE-&forceEdit=true&sandboxMode=true\n","#https://medium.com/predict/creating-a-chatbot-from-scratch-using-keras-and-tensorflow-59e8fc76be79"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5GAfrSJrs5Nb","colab_type":"code","outputId":"548656a6-e6c9-4174-8219-c2650c683ff8","executionInfo":{"status":"ok","timestamp":1586196884199,"user_tz":180,"elapsed":1249,"user":{"displayName":"Thales Fonseca","photoUrl":"","userId":"01438805462048937481"}},"colab":{"base_uri":"https://localhost:8080/","height":836}},"source":["answers"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['<START>Eu estou bem, e você?<END>',\n"," '<START>Isso é bom.<END>',\n"," '<START>Que boa notícia?<END>',\n"," '<START>Eu não sei ler.<END>',\n"," '<START>Azul<END>',\n"," '<START>Não, não é. O bolo é delicioso.<END>',\n"," '<START>Nenhuma coisa<END>',\n"," '<START>Fale-me sobre você.<END>',\n"," '<START>Você é um robô?<END>',\n"," '<START>Como é?<END>',\n"," '<START>Como você trabalha?<END>',\n"," '<START>Complexo é melhor que complicado.<END>',\n"," '<START>Simples é melhor que complexo.<END>',\n"," '<START>Parece que o seu familiar com o Zen de Python<END>',\n"," '<START>Você sabe tudo isso?<END>',\n"," '<START>Explícito é melhor que implícito.<END>',\n"," '<START>Complexo é melhor que complicado.<END>',\n"," '<START>Dispersa é melhor que denso.<END>',\n"," '<START>Casos especiais não são especiais o suficiente para quebrar as regras.<END>',\n"," '<START>Erros nunca devem passar silenciosamente.<END>',\n"," '<START>Diante da ambigüidade, recuse a tentação de adivinhar.<END>',\n"," '<START>Apesar de que maneira pode não ser óbvio à primeira vista, a menos que você seja holandês.<END>',\n"," '<START>Embora nunca tenha sido muitas vezes é melhor do que agora.<END>',\n"," '<START>Se a implementação é fácil de explicar, pode ser uma boa idéia.<END>',\n"," '<START>Eu concordo.<END>',\n"," '<START>Sou programador<END>',\n"," '<START>Eu uso Python, Java e C ++ com bastante frequência.<END>',\n"," '<START>Eu não estou Apaixonado por Java.<END>',\n"," '<START>Ele tem muitas inconsistências.<END>',\n"," '<START>Depende de como você define a vida<END>',\n"," '<START>Isso é uma definição ou uma opinião?<END>',\n"," '<START>Vá em frente e perguntar.<END>',\n"," '<START>Sou um bot.<END>',\n"," '<START>Muito interessante!<END>',\n"," '<START>Porque eu sou uma.<END>',\n"," '<START>Hm... Me baseando nos meus códigos acho que sim.<END>',\n"," '<START>Ai você ta pedindo demais.<END>',\n"," '<START>Não sou capaz de opinar.<END>',\n"," '<START>Pô, valeu!<END>',\n"," '<START>A não sei... parece programado<END>',\n"," '<START>Então... sobre isso... é meio difícil<END>',\n"," '<START>Tenho diversos nomes.<END>',\n"," '<START>Sim, um tempo atrás tavam me chamando de Gilberto<END>',\n"," '<START>Várias! sei diversas linguas.<END>',\n"," '<START>Sim, um tempo atrás tava falando alemão<END>',\n"," '<START>Recomendo!<END>',\n"," '<START>Claro, manda o papo!<END>']"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"id":"zekjl66eL9F3","colab_type":"code","colab":{}},"source":["\n","#https://medium.com/analytics-vidhya/intuitive-understanding-of-seq2seq-model-attention-mechanism-in-deep-learning-1c1c24aace1e\n","\n","\n","masking and padding\n","#https://blog.keras.io/using-pre-trained-word-embeddings-in-a-keras-model.html\n","#https://www.tensorflow.org/guide/keras/masking_and_padding\n","\n","\n","#https://github.com/lazyprogrammer/machine_learning_examples/blob/master/nlp_class3/poetry.py\n","\n","A Neural Network Approach to\n","Context-Sensitive Generation of Conversational Responses∗\n","#https://arxiv.org/pdf/1506.06714.pdf (x)\n"," \n"," \n","#https://github.com/keras-team/keras/blob/master/examples/lstm_seq2seq.py\n","\n","#http://complx.me/2016-06-28-easy-seq2seq/ (x)\n","\n","#https://github.com/samurainote/Automatic-Encoder-Decoder_Seq2Seq_Chatbot (x)\n","\n","#http://complx.me/2016-12-31-practical-seq2seq/ (x)\n","\n","#http://www.wildml.com/2016/04/deep-learning-for-chatbots-part-1-introduction/ (x)\n","\n","\n","A Persona-Based Neural Conversation Model\n","#https://arxiv.org/pdf/1603.06155.pdf()\n","\n","A Neural Conversational Model\n","#https://arxiv.org/pdf/1506.05869.pdf ()\n","\n","Memory Networks\n","#https://arxiv.org/abs/1410.3916 ()\n","\n","#https://upcommons.upc.edu/bitstream/handle/2117/117176/TFG_final_version.pdf?sequence=1&isAllowed=y ()\n","       \n","       Deep Learning Based Chatbot Models\n","----->#https://arxiv.org/pdf/1908.08835.pdf \n","\n","#https://www.kdnuggets.com/2019/11/create-vocabulary-nlp-tasks-python.html ()\n","\n","-----> #https://hub.packtpub.com/build-generative-chatbot-using-recurrent-neural-networks-lstm-rnns/ ()\n","\n","#https://blog.keras.io/a-ten-minute-introduction-to-sequence-to-sequence-learning-in-keras.html ()\n","\n","#https://medium.com/@Alibaba_Cloud/self-attention-mechanisms-in-natural-language-processing-9f28315ff905 (x)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gHxZjg2Ml1Ft","colab_type":"code","colab":{}},"source":["Attention mechanism\n","#https://towardsdatascience.com/intuitive-understanding-of-attention-mechanism-in-deep-learning-6c9482aecf4f"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NW425J6um3MY","colab_type":"text"},"source":["##8) Tests"]},{"cell_type":"code","metadata":{"id":"I4nlenrzm6-B","colab_type":"code","colab":{}},"source":["def listToString(s):  \n","    \n","    # initialize an empty string \n","    str1 = \"  \" \n","    \n","    # return string   \n","    return (str1.join(s)) \n","\n","\n","def strinToList(s):\n","  s = list(s.split(\"  \"))\n","  return s \n","\n","with open('conversations.yml') as f:\n","  conversation = [line.rstrip('\\n') for line in f]\n","\n","\n","y = []\n","x = []\n","\n","for i in range(len(conversation)):\n","  if(i % 2 == 0 and i > 2 ):\n","    y.append(conversation[i])\n","  else:\n","    if(i % 2 != 0 and i > 2):\n","      x.append(conversation[i])\n","\n","def clean_text(text):\n","    '''Clean text by removing unnecessary characters and altering the format of words.'''\n","\n","    text = text.lower()\n","    text = re.sub(r\"[-()\\\"#/@;:<>{}`+=~|.!?,]\", \"\", text)\n","    \n","    return text"],"execution_count":0,"outputs":[]}]}